---
keywords: AB;A/B;AB...n;mistakes;pitfalls;mistake;pitfall;significance;winner;statistically difference;statistical;statistical power;traffic allocation;allocation;
description: A/B 测试是大多数数字营销优化计划的基础，可帮助营销人员向其访客和客户提供经过优化的、有针对性的体验。本节概述了公司在Adobe Target中执行A/B测试时可能遇到的九个最严重的缺陷。 此外，本节还介绍了避免这些陷阱的方法，从而使您的公司可以通过这种测试工作获得更高的投资回报率 (ROI)，并对报告的 A/B 测试结果更有信心。
title: 九种常见的 A/B 测试陷阱以及避免方法
uuid: 63c47a7c-3378-4a0b-bfd5-c15865dad403
translation-type: tm+mt
source-git-commit: 91cfd46500e1f245750c651f254ee560b04b0795

---


# Ten common A/B testing pitfalls and how to avoid them{#nine-common-a-b-testing-pitfalls-and-how-to-avoid-them}

A/B 测试是大多数数字营销优化计划的基础，可帮助营销人员向其访客和客户提供经过优化的、有针对性的体验。本节概述了公司在执行A/B测试时可能遇到的十大隐患。 此外，本节还介绍了避免这些陷阱的方法，从而使您的公司可以通过这种测试工作获得更高的投资回报率 (ROI)，并对报告的 A/B 测试结果更有信心。

## Pitfall 1: Ignoring the effects of the significance level {#section_55F5577A13C6470BA1417C2B735C6B1D}

您的测试是否存在这种可能：它报告了两个选件之间的转化率有着显著差异，但实际上这种差异并不存在？这就是测试的“显著性水平”的作用所在。**&#x200B;通常，我们将这种误导性的结论称为误报；而在统计学中，则称之为“Ⅰ 类错误”（即，当原假设正确时，您错误地拒绝了该假设）。

当您指定 A/B 测试的显著性水平时，您就是在以下两种情况的容差之间进行权衡：第一，认同一种体验比另一种体验好，但事实并非如此（I 类错误或“误报”）；第二，认为两个体验之间不存在具有统计意义的差异，但实际这种差异是存在真正的（II 类错误或“漏报”）。在运行测试之前确定“置信水平”**。

测试完成后确定的“置信区间”**&#x200B;受三个关键因素影响：测试样本量、显著性水平和总体标准偏差。由于营销人员是在设计测试之前选择显著性水平，而总体标准偏差不会受到影响，因此唯一的“可控”因素就是样本量。您满意的置信区间所需的样本量，以及达到该样本量所需经历的时间，是营销人员在测试的设计过程中必须做出的关键决定。

另一个直接相关的术语“置信水平”，**&#x200B;它更多地是从正面考虑。与显著性水平相反，置信水平体现的不是您得到误报的可能性，而是您的测试不会出现这种错误的可能性。

置信水平和显著性水平直接相关，因为：

100% - 置信水平 = 显著性水平

在 A/B 测试中，营销人员经常使用 95% 的置信水平。显然，根据上述等式，显著性水平将为 5%。在测试中使用 95% 的置信水平意味着您有 5% 的机会得到误报，即：虽然选件之间实际上并没有差异，但您仍检测到具有统计意义的提升。

如下图所示，您运行的测试越多，则至少有一次测试会出现误报的可能性就越大。例如，如果使用 95% 的置信水平运行 10 次测试，则大约有 40% 的几率会检测到一个或多个误报（实际并没有提升：Pr（至少一个误报）= 1 - Pr（没有误报）= 1 - 0.95^10 = 40%）。

![](assets/pitfalls1.png)

在营销组织中，95% 通常是误报和漏报这两种风险之间比较合理的一种权衡。

但是，以下两种情况需要密切关注显著性水平及其对测试结果的影响：测试后分段以及测试多个选件。

* **测试后分段：**&#x200B;营销人员经常会在 A/B 测试结束后，根据访客区段对测试结果进行切割分析。常见区段包括：浏览器类型、设备类型、地理区域、一天中的不同时段以及新访客和回访访客。这种操作被称为测试后分段，可对访客区段进行非常详细的分析和解读。反过来，营销人员可以利用这些分析来创建更具针对性、更相关的差异化内容。

   如果转化率没有实际差异，则每测试一个区段时，误报的概率等于显著性水平。而且，如前所述，您运行的测试越多，在这些测试中遇到至少一个误报的可能性就越大。实质上，每个测试后区段都代表一次单独的测试。如果显著性水平为 5%，则平均而言，每查看 20 个测试后区段，您就会遇到一个误报。上图显示了这种可能性是如何增加的。

   如前所述，您运行的测试越多，在这些测试中遇到至少一个误报的可能性就越大。实质上，每个测试后区段都代表一次单独的测试，而这会增加误报的可能性。如果区段相互关联，则这种增加会更明显。

   那么，是否可以不进行测试后分段？答案是否定的，测试后分段非常重要。要避免测试后分段出现累积误报的问题，在确定测试后区段后，应考虑在新的测试中对该区段进行测试。或者，您也可以应用下文所讨论的邦弗朗尼校正 (Bonferroni correction)。

* **测试多个选件：**&#x200B;营销人员经常对两个以上的选件（或体验）同步进行对比测试。这就是为什么您有时会看到 A/B 测试解决方案被称为 A/B/n 测试，其中 n 是同步测试的选件数量。

   需要注意的是，如上文所述，*每一个*&#x200B;测试选件都具有一个等于显著性水平的误报率。同样，如果同一个测试环境中有多个选件彼此对照，那么实际上您正在有效运行多个测试。例如，如果您在 A/B/C/D/E 测试中比较五个选件，则可以有效地形成四组对比：控制选件与 B 的对比、控制选件与 C 的对比、控制选件与 D 的对比、控制选件与 E 的对比。那么当置信水平为 95% 时，出现误报的可能性概率实际是 18.5%，而不是 5%。2

   要将整体置信水平保持在 95% 并避免出现此问题，请应用邦弗朗尼校正。使用此校正时，只需将显著性水平除以比较次数即可得出达到 95% 置信水平所需的显著性水平。

   在将邦弗朗尼校正应用于上述示例时，您将使用 5%/4 = 1.25% 的显著性水平，这等同于单次测试 98.75% (100% - 1.25% = 98.75%) 的置信水平。在上述示例运行四个测试的情况下，这项调整会将有效置信水平维持在 95%。

## Pitfall 2: Declaring winners of multiple offer tests with no statistically significant difference {#section_FA83977C71DB4F69B3D438AF850EF3B6}

在对多个选件进行测试时，营销人员通常会将具有最高提升度的选件确定为测试获胜选件（即“入选者”），即使入选者和第二名之间不存在具有统计意义的显著差异。当替代选件之间的差异小于替代选件与控制选件之间的差异时，会出现这种情况。下图说明了此概念，黑色误差线表示 95% 的提升度置信区间。每个选件相对于控制选件的真实提升度有 95% 的可能包含在置信区间内，即误差线所示的范围内。

![](assets/pitfalls2.png)

在测试期间，选件 A 和 B 观察到的提升度最高，并且在未来的测试中，选件 C 的提升度不太可能超过这两个选件，因为 C 的置信区间甚至未与 A 或 B 的置信区间有任何重叠。但是，对于 A 和 B 来说，即使选件 A 在测试期间观察到的提升度最高，但由于它们的置信区间重叠，因此选件 B 在未来的测试中，有可能会表现得更好。

由此得出的结论是，选件 A 和 B 都应该被视为测试的入选者。

运行足够长时间的测试以识别替代选件的真实相对性能通常是不可行的，而且替代选件之间的性能差异有时会太小而不足以对转化率产生实质性影响。在这种情况下，您可以将结果解释为平局，然后使用其他考虑因素来确定要执行的选件，例如从策略层面考虑，或者是否与页面的其他元素相得益彰。在进行多个测试时，您必须对选中多个入选者持开放态度，这样在某些情况下可以为您的网站开发方向创造出其他可能性。

请注意，如果您确实要选择转化率最高的选件，则可将所有选件与其他选件互相进行比较。在上面的示例中，您有 n = 5 个选件 - 则必须进行 n(n-1)/2 次比较，即 5*(5-1)/2 = 10 次比较。此时，根据邦弗朗尼校正，测试的显著性水平应为 5%/10 = 0.5%，相当于 99.5% 的置信水平。但是，如此高的置信水平所要求的测试时间可能会太长以致无法达到。

## Pitfall 3: Ignoring the effects of statistical power {#section_0D517079B7D547CCAA75F80981CBE12A}

统计功效是在测试中检测出选件之间转化率真实差异的概率。由于转化事件存在随机性，因此即使两个选件之间的转化率在长期测试中存在实际差异，该测试可能也不会显示具有统计意义的显著差异。可以认为这就是运气不好或纯属偶然。我们将这种未能检测到转化率真实差异的情况称为漏报或 II 类错误。

以下两个关键因素决定了测试的功效：第一个是样本量，即测试中包含的访客数量。第二个是您希望测试检测到的转化率差异的量级。比较直观地说，如果您只想检测到较大的转化率差异，那么在测试中，实际可以检测到这种较大差异的可能性就要高得多 - 这与您透过一个用纸巾折成的纸筒在客厅里看见一头大象和一只苍蝇的概率类似。那么，您想要检测到的差异越小，需要的样本量就越大，也因此，获得更大的样本量所需的时间就越长。

现今，营销人员进行了大量的低功效测试。换句话说，他们使用的样本量过小。这意味着即使转化率实际存在实质性差异，他们也很难检测到正确报告的正样例。事实上，如果您不断地进行低功效的测试，则误报数量会与正确报告的正样例数量相当，甚至大大超过。这通常会导致对网站执行无变化更改（浪费时间），或者是执行实际上会降低转化率的更改。

![](assets/pitfalls3.png)

要避免进行低功效测试，请考虑使用典型的高功效测试标准，包括将置信水平设为 95%，统计功效设为 80%。在这样的测试中，95% 的概率可避免出现误报，80% 的概率可避免出现漏报。

## 第4步：使用单尾测试 {#section_8BB136D1DD6341FA9772F4C31E9AA37C}

当显著性水平一定时，如要在多个选件中确定入选者，那么单侧检验所需观察到的选件之间的转化率差异更小。这似乎很有吸引力，因为与使用双侧检验相比，单侧检验可以更早地确定入选者。但俗话说，“没有免费的午餐”，单侧检验是有代价的。

例如，在一个单侧检验中，您测试的是选件 B 是否比选件 A 更好。测试的方向必须在测试开始之前确定，或者使用统计学的说法，要进行“先验”。换句话说，您必须在开始测试&#x200B;*之前*，决定是测试 B 优于 A 还是 A 优于 B。但是，如果您是先查看了 A/B 测试的结果并看到 B 优于 A，*然后*&#x200B;决定进行一个单侧检验来看这种差异是否具有统计意义，那么您就违反了统计测试背后的假设。违反测试的假设意味着您的置信区间不可靠，并且测试的误报率比您预期的要高。

您可以将单侧检验看做是一种已经由裁判做出决定、只是对该选件进行试验的测试。在单侧检验中，您已经确定了入选选件，而且只是想证明这一点，而不是向每个体验提供平等的机会来证明自己可以是入选者。单侧检验只应在这种极少发生的情况下使用：您只关注某个选件是否优于其他选件，而不是其他选件优于某个选件。要避免出现单侧检验问题，请使用始终运用双侧检验的 A/B 测试解决方案，例如 [!DNL Adobe Target]。

## 皮特福5:监视测试 {#section_EA42F8D5967B439284D863C46706A1BA}

营销人员会时刻监控 A/B 测试，直到确定测试结果为止。毕竟，为什么要在已获得统计意义后进行测试？

遗憾地是，这并不是那样简单。我们希望监控测试不会带来不利影响，但事实证明，监控结果对测试的有效统计意义会产生不利影响。它实际上大大增加了误报的可能性，并使置信区间不可信。

这可能会让人感到困惑。听上去似乎是，仅仅是在测试过程中看一下结果，就可能导致它们失去其统计意义。但事实并非完全如此。让我们通过一个示例来解释原因。

假设您模拟两个选件的 10,000 个转化事件，其中两个选件的转化率均为 10%。由于转化率相同，因此当您对这两个选件相互进行测试时，应该检测到转化率提升度没有差异。如果使用 95% 的置信区间，当收集所有 10,000 个观测值之后，测试结果为预期的 5% 误报率。因此，如果我们运行 100 个这样的测试，则我们平均会得到 5 个误报（实际上，在此示例中，所有的正都是错误的，因为两个选件之间的转化率没有差异）。但是，如果我们在测试过程中对测试进行 10 次评估（每 1,000 个观测值评估一次），结果会显示误报率高达 16%。对测试进行监控使出现误报的可能性增加了三倍以上！这是怎么回事？

要理解出现这种情况的原因，您必须考虑在检测到具有统计意义的结果时和未检测到具有统计意义的结果时，采取的操作并不不同。当检测到具有统计意义的结果时，您会停止测试并宣布入选者。但是，如果该结果不具有统计意义，则会继续测试。这种情况极易偏向于积极的结果，这样就扭曲了测试的有效显著性水平。

要避免此问题，您应该在开始测试之前，先确定足够的测试运行时间。虽然在测试过程中查看测试结果以确保测试正确运行是可以的，但在达到所需访客数量之前，请勿得出结论或停止测试。换言之，不要作弊！

## 皮特福6:过早停止测试 {#section_DF01A97275E44CA5859D825E0DE2F49F}

如果在测试的前几天中，就有一个选件的表现大大优于或弱于其他选件，那么很有可能在此时即停止测试。但是，当观察数量较低时，很有可能只是偶然观察到正或负的提升，因为转化率只是少数访客的平均值。随着测试收集的数据点越来越多，转化率会逐渐靠近真正的长期值。

下图显示了五个具有相同长期转化率的选件。选件 B 在前 2000 名访客时的转化率较差，并且在预计转化率回到真正的长期转化率之前花费了较长时间。

![](assets/pitfalls4.png)

这种现象被称为“趋均数回归”，如果在测试的最初几天表现良好的选件无法长期保持这种性能水平，则会导致让人失望的结果。此外，也有可能因为某个选件恰巧在测试早期表现不佳，而未被选中进行实施，从而导致收入上的损失。

与监控测试陷阱类似，避免这些问题的最好方法是在运行测试之前确定足够的访客数量，然后一直运行测试直到选件已经向达到此数量的所有访客展示。

## 皮特福7:在测试期间更改流量分配 {#allocation}

我们建议您不要更改测试期间的流量分配百分比，因为这可能会歪斜测试结果，直到数据正常化。
例如，假设您有一个A/B测试活动，其中80%的流量分配给体验A（控件）,20%的流量分配给体验B。在测试期间，您将每个体验的分配更改为50%。 几天后，您将流量分配更改为100%，改为体验B。

在此方案中，如何将用户分配到体验？

如果您手动将体验B的分配拆分更改为100%，则最初分配到体验A（控件）的访客将保留在最初分配的体验（体验A）中。 流量分配的变化仅影响新进入者。

如果要更改百分比或极大地影响每个体验的访客流量，我们建议您创建新活动或复制活动，然后编辑流量分配百分比。

如果您在测试期间更改了不同体验的百分比，则数据需要几天才能正常化，尤其是当许多购买者正在返回访客时。
另一个示例是，如果A/B测试的流量分配分为50/50，然后您将分配更改为80/20，则在更改后的前几天，结果可能看起来有偏差。 如果转化的平均时间很长，即某人需要数小时甚至数天才能购买产品，则这些延迟的转化可能会影响您的报告。 因此，在第一个体验中，从50%到80%，平均转化时间为两天，只有50%的人口的访客在测试的第一天进行转化，尽管今天有80%的人口进入该体验。 这使得转化率看上去一落千丈，但在80%的访客花了两天时间转化后，转化率将再次正常化。

## Pitfall 8: Not considering novelty effects {#section_90F0D24C40294A8F801B1A6D6DEF9003}

如果我们运行测试的时间不充分，可能还会发生其他意想不到的情况。此时的问题就不是统计问题；而只是访客对变化做出的反应。如果您更改了网站中某个早已被广泛接受的部分，则旧访客可能会因为他们以往熟悉的工作流发生了改变而排斥使用新选件。这可能会暂时导致性能优秀的新选件其实施效果不理想，直到旧访客逐渐习惯此选件为止 - 这就是为了新的优秀选件带来的长期利益，而需要付出的较小代价。

要确定新的选件是因为新奇效应还是因为它确实较差而表现不佳，您可以将访客分为新访客和旧访客，然后比较转化率。如果只是新奇效应，则新选件将获得新访客的青睐。并且最终，随着旧访客习惯了所做更改，此选件也终将获得他们的青睐。

新奇效应也会逆向发挥作用。通常，访客会对更改做出积极的反应，因为它引入了新内容。过了一段时间后，随着新内容变得陈旧或不再令访客感到兴奋，其转化率会下降。尽管这种效应难以识别，但仔细监控转化率的变化是检测到这一点的关键。

## Pitfall 9: Not considering differences in the consideration period {#section_B166731B5BEE4E578816E351ECDEA992}

考虑期是指从 A/B 测试解决方案向访客展示选件到该访客实现转化之间的时间段。对于会实际影响考虑期的选件来说，这一点很重要 - 例如，含有截止期限的选件，如“限时优惠 - 本周日前购买”。

这类选件可以促使访客更快地转化，并且如果在选件到期后立即停止测试，这类选件将会获益，因为替代选件可能会有更长的截止日期或没有截止日期，因此需要更长的考虑期。替代选件将会在测试结束后的时段内进行转化，但如果您在截止日期结束时停止测试，则后来进一步的转化不会计入测试转化率。

下图显示了两个不同访客在周日下午在同一时间看到的两个选件。选件 A 的考虑期较短，该访客在当天晚些时候便已转化。但是，选件 B 的考虑期较长，查看选件 B 的访客对该选件考虑了一段时间，并最终在周一上午形成转化。如果您在周日晚上停止测试，与选件 A 关联的转化会计入选件 A 的转化量度，而与选件 B 关联的转化则不会计入选件 B 的转化量度。这使选件 B 处于明显的劣势。

![](assets/pitfalls5.png)

要避免此陷阱，可在停止要测试的新条目后，再给予查看过测试选件的访客一些时间，使他们能够形成转化。这样做即可让您对这些选件进行公平比较。

## Pitfall 10: Using metrics that do not reflect business objectives {#section_F0CD6DC7993B4A6F9BEEBB31CD1D9BEE}

营销人员可能会倾向于使用上层漏斗中的高流量低方差转化量度，例如点进率 (CTR)，以更快地达到足够数量的测试转化。但是，请仔细考虑点进率是否能够真正代表您想获得的业务目标。点进率较高的选件很容易导致收入减少。当选件吸引的访客购买倾向较低时，或者只是因为选件本身就会导致较低的收入时（例如折扣选件），就会发生这种情况。

![](assets/pitfalls6.png)

以下面的滑雪选件为例。它产生的点进率比骑车选件高得多，但由于访客在选择骑车选件时平均花费的钱更多，因此将骑车选件提供给特定访客所获得的预计收入更高。因此，将 CTR 作为量度的 A/B 测试将选择不会让收入最大化的选件，而这与最基本的业务目标相悖。

![](assets/pitfalls7.png)

要避免此问题，请仔细监控您的业务量度以确定选件在业务方面的影响，或者更好的做法是，尽可能使用更接近您业务目标的量度。

## Conclusion: Success with A/B testing by recognizing and stepping around the pitfalls {#section_54D33248163A481EBD4421A786FE2B15}

在了解了常见的 A/B 测试陷阱后，我们希望您能够识别您可能会在何时以及何处遇到这些问题。同时，我们也希望通过上面的介绍，让您更好地理解到 A/B 测试所涉及的一些统计学概念和概率概念，一般人会认为似乎只有数学专业的人才会接触这些概念。

以下步骤可帮助您避免落入这些陷阱，并将重点聚焦在如何通过 A/B 测试取得更好的结果：

* 根据相关业务目标，仔细考虑要测试的正确量度。
* 在测试开始前决定置信水平，并在测试结束后评估结果时坚持以该阈值为参考。
* 在测试开始前计算样本量（访客数量）。
* 等待达到计算的样本量之后再停止测试。
* 在进行测试后分段或评估多个替代选件时调整置信水平 - 例如，使用邦弗朗尼校正。

